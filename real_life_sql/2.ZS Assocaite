You have a table, logins(user_id, login_date). 
Find all users who have logged in for at least 3 consecutive days 
at any time (show user_id and first day of such a streak).

----------------------
row number-consecutive increasing seq lead to same number which can be used for group by
-----------------------

WITH dated_logins AS (
    SELECT
        user_id,
        login_date,
        DATE_SUB(login_date, INTERVAL ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY login_date) DAY) AS streak_anchor
    FROM
        logins
),
streaks AS (
    SELECT
        user_id,
        MIN(login_date) AS first_day,
        COUNT(*) AS streak_length
    FROM
        dated_logins
    GROUP BY
        user_id, streak_anchor
    HAVING
        COUNT(*) >= 3
),
earliest_streak AS (
    SELECT
        user_id,
        MIN(first_day) AS first_streak_day
    FROM
        streaks
    GROUP BY
        user_id
)
SELECT
    user_id,
    first_streak_day
FROM
    earliest_streak;

----------------------------------

from pyspark.sql.functions import col, row_number, min as _min, count as _count, expr
from pyspark.sql.window import Window

window_spec = Window.partitionBy("user_id").orderBy("login_date")

df_with_rownum = logins_df.withColumn("rn", row_number().over(window_spec))
df_with_group = df_with_rownum.withColumn("streak_group", expr("login_date - interval rn days"))

streaks = df_with_group.groupBy("user_id", "streak_group") \
    .agg(
        _min("login_date").alias("first_day"),
        _count("*").alias("streak_length")
    ) \
    .filter(col("streak_length") >= 3)

result = streaks.groupBy("user_id") \
    .agg(_min("first_day").alias("first_streak_day"))