1571. Warehouse Manager

SQL Schema 
Table: Warehouse

+--------------+---------+
| Column Name  | Type    |
+--------------+---------+
| name         | varchar |
| product_id   | int     |
| units        | int     |
+--------------+---------+
(name, product_id) is the primary key for this table.
Each row of this table contains the information of the products in each warehouse.
 

Table: Products

+---------------+---------+
| Column Name   | Type    |
+---------------+---------+
| product_id    | int     |
| product_name  | varchar |
| Width         | int     |
| Length        | int     |
| Height        | int     |
+---------------+---------+
product_id is the primary key for this table.
Each row of this table contains the information about the product dimensions (Width, Lenght and Height) in feets of each product.
 

Write an SQL query to report, How much cubic feet of volume does the inventory occupy in each warehouse.

warehouse_name
volume
Return the result table in any order.

The query result format is in the following example.

 

Warehouse table:
+------------+--------------+-------------+
| name       | product_id   | units       |
+------------+--------------+-------------+
| LCHouse1   | 1            | 1           |
| LCHouse1   | 2            | 10          |
| LCHouse1   | 3            | 5           |
| LCHouse2   | 1            | 2           |
| LCHouse2   | 2            | 2           |
| LCHouse3   | 4            | 1           |
+------------+--------------+-------------+

Products table:
+------------+--------------+------------+----------+-----------+
| product_id | product_name | Width      | Length   | Height    |
+------------+--------------+------------+----------+-----------+
| 1          | LC-TV        | 5          | 50       | 40        |
| 2          | LC-KeyChain  | 5          | 5        | 5         |
| 3          | LC-Phone     | 2          | 10       | 10        |
| 4          | LC-T-Shirt   | 4          | 10       | 20        |
+------------+--------------+------------+----------+-----------+

Result table:
+----------------+------------+
| warehouse_name | volume     |
+----------------+------------+
| LCHouse1       | 12250      |
| LCHouse2       | 20250      |
| LCHouse3       | 800        |
+----------------+------------+
Volume of product_id = 1 (LC-TV), 5x50x40 = 10000
Volume of product_id = 2 (LC-KeyChain), 5x5x5 = 125
Volume of product_id = 3 (LC-Phone), 2x10x10 = 200
Volume of product_id = 4 (LC-T-Shirt), 4x10x20 = 800
LCHouse1: 1 unit of LC-TV + 10 units of LC-KeyChain + 5 units of LC-Phone.
          Total volume: 1*10000 + 10*125  + 5*200 = 12250 cubic feet
LCHouse2: 2 units of LC-TV + 2 units of LC-KeyChain.
          Total volume: 2*10000 + 2*125 = 20250 cubic feet
LCHouse3: 1 unit of LC-T-Shirt.
          Total volume: 1*800 = 800 cubic feet.

-------------------------------------------

SELECT
    w.name AS warehouse_name,
    COALESCE(SUM(w.units * p.Width * p.Length * p.Height), 0) AS volume
FROM Warehouse w
LEFT JOIN Products p
    ON w.product_id = p.product_id
GROUP BY w.name;

------------------------------------------------

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, sum as _sum, coalesce, lit

spark = SparkSession.builder.appName("WarehouseVolume").getOrCreate()

# Sample data
warehouse_data = [
    ("LCHouse1", 1, 1),
    ("LCHouse1", 2, 10),
    ("LCHouse1", 3, 5),
    ("LCHouse2", 1, 2),
    ("LCHouse2", 2, 2),
    ("LCHouse3", 4, 1),
]
warehouse_columns = ["name", "product_id", "units"]

products_data = [
    (1, "LC-TV", 5, 50, 40),
    (2, "LC-KeyChain", 5, 5, 5),
    (3, "LC-Phone", 2, 10, 10),
    (4, "LC-T-Shirt", 4, 10, 20),
]
products_columns = ["product_id", "product_name", "Width", "Length", "Height"]

warehouse_df = spark.createDataFrame(warehouse_data, warehouse_columns)
products_df = spark.createDataFrame(products_data, products_columns)

joined_df = warehouse_df.join(
    products_df, warehouse_df.product_id == products_df.product_id, "left"
).withColumn(
    "product_volume",
    col("units") * col("Width") * col("Length") * col("Height")
)

result_df = joined_df.groupBy("name").agg(
    coalesce(_sum("product_volume"), lit(0)).alias("volume")
).withColumnRenamed("name", "warehouse_name")

result_df.show()
<!-- 
When you perform an aggregation like sum, if all values being summed are NULL (for example, due to a left join with no matches), the result will be NULL.
Using coalesce(sum(...), lit(0)) inside agg ensures that if the sum is NULL, it will be replaced with 0.
This is especially important for reporting, where you want to show 0 instead of NULL for missing data. -->

-----------------------

The when() function always requires a condition (which is usually built using a col() object or an expression involving DataFrame columns).
when() is not used independently; it is used to build a new column or inside .withColumn() or .select().

when() is used with column expressions, not as a standalone function. returns col() object
It is typically used inside .withColumn() or .select() to create or transform columns.

products_df = products_df.withColumn(
    "Width",
    coalesce(col("Width"), lit(0))
)