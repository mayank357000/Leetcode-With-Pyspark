3246. Premier League Table Ranking
Description
Table: TeamStats

+++
\| team_id          \| int     \|
\| team_name        \| varchar \|
\| matches_played   \| int     \|
\| wins             \| int     \|
\| draws            \| int     \|
\| losses           \| int     \|
+++-++-+--+
\| team_id \| team_name       \| matches_played \| wins \| draws \| losses \|
+--++-++-+--+

Output:

+--+--++-+
\| 2       \| Liverpool       \| 20     \| 1        \|
\| 1       \| Manchester City \| 20     \| 1        \|
\| 3       \| Chelsea         \| 18     \| 3        \|
\| 4       \| Arsenal         \| 16     \| 4        \|
\| 5       \| Tottenham       \| 14     \| 5        \|
+--+--+----+
Explanation:

Manchester City and Liverpool both have 20 points (6 wins * 3 points + 2 draws * 1 point), so they share position 1.
Chelsea has 18 points (5 wins * 3 points + 3 draws * 1 point) and is position 3rd.
Arsenal has 16 points (4 wins * 3 points + 4 draws * 1 point) and is position 4th.
Tottenham has 14 points (3 wins * 3 points + 5 draws * 1 point) and is position 5th.
The output table is ordered by points in descending order, then by team_name in ascending order.

----------------------
SELECT 
    team_id, 
    team_name, 
    (wins * 3 + draws) AS points,
    DENSE_RANK() OVER (
        ORDER BY (wins * 3 + draws) DESC, team_name ASC
    ) AS rank
FROM 
    TeamStats
ORDER BY 
    points DESC, team_name ASC;

----------------------------

from pyspark.sql.window import Window
from pyspark.sql.functions import col, dense_rank

df = df.withColumn("points", col("wins") * 3 + col("draws"))

windowSpec = Window.orderBy(col("points").desc(), col("team_name").asc())

df = df.withColumn("rank", dense_rank().over(windowSpec)) \
       .orderBy(col("points").desc(), col("team_name").asc()) \
       .select("team_id", "team_name", "points", "rank")

#In standard SQL, you can’t use an alias (like points) 
#inside the same SELECT clause’s OVER() window function
#PySpark doesn’t suffer from that restriction