512. Game Play Analysis II
Table: Activity

+--------------+---------+
| Column Name  | Type    |
+--------------+---------+
| player_id    | int     |
| device_id    | int     |
| event_date   | date    |
| games_played | int     |
+--------------+---------+
(player_id, event_date) is the primary key of this table.
This table shows the activity of players of some game.
Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on some day using some device.

Write a SQL query that reports the device that is first logged in for each player.

The query result format is in the following example:

Activity table:
+-----------+-----------+------------+--------------+
| player_id | device_id | event_date | games_played |
+-----------+-----------+------------+--------------+
| 1         | 2         | 2016-03-01 | 5            |
| 1         | 2         | 2016-05-02 | 6            |
| 2         | 3         | 2017-06-25 | 1            |
| 3         | 1         | 2016-03-02 | 0            |
| 3         | 4         | 2018-07-03 | 5            |
+-----------+-----------+------------+--------------+

Result table:
+-----------+-----------+
| player_id | device_id |
+-----------+-----------+
| 1         | 2         |
| 2         | 3         |
| 3         | 1         |
+-----------+-----------+

--------------------------------------
least ya earliest aya toh min use kr skte hai group by use krke
-----------------------------
WITH cte1 AS (
    SELECT player_id, device_id, event_date,
           ROW_NUMBER() OVER (PARTITION BY player_id ORDER BY event_date) AS rn
    FROM Activity
)
SELECT player_id, device_id
FROM cte1
WHERE rn = 1;

-------------------------
from pyspark.sql import Window,SparkSession
from pyspark.sql.functions import col, row_number

window = Window.partitionBy(col("player_id")).orderBy(col("event_date").asc())

df = df.withColumn("ROW_NUMBER", row_number().over(window)) \
       .filter(col("ROW_NUMBER") == 1) \
       .select("player_id", "device_id")