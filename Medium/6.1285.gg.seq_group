1285. Find the Start and End Number of Continuous Ranges
SQL Schema 
Table: Logs

+---------------+---------+
| Column Name   | Type    |
+---------------+---------+
| log_id        | int     |
+---------------+---------+
id is the primary key for this table.
Each row of this table contains the ID in a log Table.

Since some IDs have been removed from Logs. Write an SQL query to find the start and end number of continuous ranges in table Logs.

Order the result table by start_id.

The query result format is in the following example:

Logs table:
+------------+
| log_id     |
+------------+
| 1          |
| 2          |
| 3          |
| 7          |
| 8          |
| 10         |
+------------+

Result table:
+------------+--------------+
| start_id   | end_id       |
+------------+--------------+
| 1          | 3            |
| 7          | 8            |
| 10         | 10           |
+------------+--------------+
The result table should contain all ranges in table Logs.
From 1 to 3 is contained in the table.
From 4 to 6 is missing in the table
From 7 to 8 is contained in the table.
Number 9 is missing in the table.
Number 10 is contained in the table.

---------------------------
row number seq and diff of conscutive seq will be same for a grp 
-----------------

WITH Ranked AS (
    SELECT 
        log_id,
        log_id - ROW_NUMBER() OVER (ORDER BY log_id) AS diff
    FROM Logs
)
SELECT 
    MIN(log_id) AS start_id,
    MAX(log_id) AS end_id
FROM Ranked
GROUP BY diff
ORDER BY start_id;

------------------
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, row_number, min as min_, max as max_, expr
from pyspark.sql.window import Window

# list of tuples, strings
data = [(1,), (2,), (3,), (7,), (8,), (10,)]
columns = ["log_id"]

spark = SparkSession.builder.getOrCreate()
df = spark.createDataFrame(data, columns)

w = Window.orderBy("log_id")

df_ranked = df.withColumn("row_num", row_number().over(w)) \
              .withColumn("diff", expr("log_id - row_num"))

df_ranges = df_ranked.groupBy("diff") \
    .agg(min_("log_id").alias("start_id"),
         max_("log_id").alias("end_id")) \
    .orderBy("start_id")

df_ranges.show()