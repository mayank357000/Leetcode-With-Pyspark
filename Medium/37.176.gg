176. Second Highest Salary
Table: Employee

+-------------+------+
| Column Name | Type |
+-------------+------+
| id          | int  |
| salary      | int  |
+-------------+------+
id is the primary key (column with unique values) for this table.
Each row of this table contains information about the salary of an employee.

Write a solution to find the second highest distinct salary from the Employee table. If there is no second highest salary, return null (return None in Pandas).

The result format is in the following example.

Example 1:

Input: 
Employee table:
+----+--------+
| id | salary |
+----+--------+
| 1  | 100    |
| 2  | 200    |
| 3  | 300    |
+----+--------+
Output: 
+---------------------+
| SecondHighestSalary |
+---------------------+
| 200                 |
+---------------------+
Example 2:

Input: 
Employee table:
+----+--------+
| id | salary |
+----+--------+
| 1  | 100    |
+----+--------+
Output: 
+---------------------+
| SecondHighestSalary |
+---------------------+
| null                |
+---------------------+

-------------------------------------------- 
MAX() over an empty set â†’ NULL 
------------------------------------

SELECT 
    MAX(salary) AS SecondHighestSalary
FROM 
    Employee
WHERE 
    salary < (SELECT MAX(salary) FROM Employee);

------------------------------------------

window=Window.orderBy(col("salary").desc())

ranked_df=df.withColumn("rank",dense_rank().over(window))

second_high=ranked_df.filter(col("rank")==2).select(col("salary").alias("SecondHighestSalary"))

result = second_highest_df.collect()
if result:
    print(result[0]["SecondHighestSalary"])
else:
    print(None)

OR 


max_salary = df.agg(spark_max("salary")).collect()[0][0]

# Filter salaries less than max, then get max of those
second_highest_df = df.filter(col("salary") < max_salary).agg(
    spark_max("salary").alias("SecondHighestSalary")
)

OR can use join to avoid this collecting

from pyspark.sql.functions import lit

max_salary_df = df.agg(spark_max("salary").alias("max_salary"))

second_highest_df = df.crossJoin(max_salary_df) \
    .filter(col("salary") < col("max_salary")) \
    .agg(spark_max("salary").alias("SecondHighestSalary"))

OR 

use spark sql

df.createOrReplaceTempView("employees")

spark.sql("""
  SELECT MAX(salary) AS SecondHighestSalary
  FROM employees
  WHERE salary < (SELECT MAX(salary) FROM employees)
""")

-------------------in pyspakr to get single agg value comaprision we chave to collect and then compare or use something like above

